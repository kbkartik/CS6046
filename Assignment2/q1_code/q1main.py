# -*- coding: utf-8 -*-
"""FTRL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CB8irCOI-7Gc36zKw2aF5T3AK1_E67QJ
"""

#cp /content/drive/MyDrive/assignments/Dataset_Z.txt /content/

import numpy as np
import time
import matplotlib.pyplot as plt
from tqdm import tqdm


from solver import Solver
from quadratic_ftrl import QuadraticRegularizer
from entropic_ftrl import EntropicRegularizer
from ftpl import RandomizedRegularizer

# Give path to dataset
PATH = '/content/Dataset_Z.txt'

# Copy values from text file into an array
dataset = open(PATH, 'r')
adversary = None
for i, line in tqdm(enumerate(dataset)):
  vals = np.array(line.strip().split(',')).astype(np.float)
  vals = vals.reshape(1, -1)
  if adversary is None:
    adversary = vals
  else:
    adversary = np.append(adversary, vals, axis=0)     


# Number of iterations
T = 10000

# Number of dimensions
d = 1000
epochs = 1
dataset = adversary.copy()

# Max L2-norm of the datapoints in the dataset
# to calculate learning rate of Quadratic and Entropic Regularizer
L2 = np.max(np.linalg.norm(dataset, axis=1))
eta = 1/(L2*np.sqrt(2*T))
itrs = range(1, T+1)

# Initializing and running Quadratic Regularizer experiment
model_qftrl = QuadraticRegularizer(d, T, eta, epochs, dataset)
model_qftrl.run()


# Initializing and running Entropic Regularizer experiment
model_eftrl = EntropicRegularizer(d, T, eta, epochs, dataset)
model_eftrl.run()

# Initializing and running Randomized Regularizer experiment
epochs = 1000 # To get expected regret
model_ftpl = RandomizedRegularizer(d, T, epochs, dataset)
model_ftpl.run()


# Plot regret bound graphs
plt.figure(figsize=(8, 8))
plt.plot(itrs, np.mean(model_qftrl.regret, 0), color='blue')
plt.xlabel("Number of iterations")
plt.ylabel("Regret")
plt.title("FTRL (Quadratic regularizer) regret")
plt.savefig('ftrl_quad.png')

plt.figure(figsize=(8, 8))
plt.plot(itrs, np.mean(model_eftrl.regret, 0), color='red')
plt.xlabel("Number of iterations")
plt.ylabel("Regret")
plt.title("FTRL (Entropic regularizer) regret")
plt.savefig('ftrl_entropic.png')

plt.figure(figsize=(8, 8))
plt.plot(itrs, np.mean(model_ftpl.regret, 0), color='green')
plt.xlabel("Number of iterations")
plt.ylabel("Regret")
plt.title("FTPL (Randomized regularizer) regret")
plt.savefig('ftpl_randomized.png')

"""# Hold

def proj_on_simplex(self, p_t_hat):
    u = sorted(p_t_hat)
    rho = 0
    for j in range(self.dim):
      value = u[j] + (1-sum(u[:j+1]))/(j+1)
      if value > 0 and j > rho:
        rho = j

    rho += 1
    lamda = (1-sum(u[:rho]))/rho

    x = np.zeros((self.dim,))
    for i in range(self.dim):
      x[i] = max(p_t_hat[i]+lamda, 0)

    return x
"""